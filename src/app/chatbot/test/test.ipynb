{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "db = Neo4jGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from graph import calculate_risk_coefficients, car_analysis, go_to_searcher\n",
    "from guardian import Guardian,  PictureAnalyzer\n",
    "from query_generator import create_query_generator\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0\n",
    ")\n",
    "picture_analysis = PictureAnalyzer(llm).create_picture_analyzer()\n",
    "query_gen = create_query_generator(llm, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardian = Guardian(llm, [go_to_searcher])\n",
    "llm_with_guardian = guardian.create_guardian()\n",
    "search_node = ToolNode([go_to_searcher])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_node = ToolNode([calculate_risk_coefficients, car_analysis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caller import Caller\n",
    "\n",
    "mini_llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "caller = Caller(mini_llm, [calculate_risk_coefficients, car_analysis]).create_caller()\n",
    "\n",
    "app_tools = {\n",
    "    'db': db,\n",
    "    'caller': caller,\n",
    "    'guardian': llm_with_guardian,\n",
    "    'cypher': query_gen,\n",
    "    'picture': picture_analysis,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph import State, compile_graph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "\n",
    "graph = StateGraph(State)\n",
    "memory = MemorySaver()\n",
    "\n",
    "app = compile_graph(graph, memory, search_node, tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}, \"recursion_limit\": 15}\n",
    "config['configurable'].update(app_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"Dimmi di Vito Teci\"\n",
    "\n",
    "events = app.astream(\n",
    "    {\"messages\": (\"user\", user_input), \"is_picture\": False}, config=config, stream_mode=\"values\",\n",
    ")\n",
    "async for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "    final_message = event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"https://immagini.alvolante.it/sites/default/files/styles/anteprima_640/public/dasapere_galleria/2024/07/targa-italiana-987.jpg\"\n",
    "import httpx\n",
    "import base64\n",
    "image_data = base64.b64encode(httpx.get(image_url).content).decode(\"utf-8\")\n",
    "image = f\"{image_data}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = app.astream(\n",
    "    {\"messages\": (\"user\", image), \"is_picture\": True}, config=config, stream_mode=\"values\",\n",
    ")\n",
    "async for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "    final_message = event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_message[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = app.get_state(config).values\n",
    "from pprint import pprint\n",
    "pprint(snapshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.get_state(config).values['messages'].extend(final_message['messages'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(app.get_state(config).values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
